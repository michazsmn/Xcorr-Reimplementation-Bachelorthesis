\documentclass[11pt]{article}
\usepackage[sorting=none]{biblatex}
\usepackage{graphicx} 
\usepackage[font=scriptsize,labelfont=bf]{caption}
\usepackage[a4paper, total={5.5in, 8.5in}]{geometry}
\usepackage{cleveref}
\usepackage{wrapfig}
\usepackage{subcaption}


\sloppy

\addbibresource{bibliography.bib}

\title{Xcorr Reimplementation Bachelorthesis}
\author{Michael zusmanovskiy}
\date{November 2024}

\begin{document}


\begin{titlepage}
    \begin{center}
        \LARGE
        Applied Computer Science

        \vspace{1cm}
        
        \LARGE
        Bachelorthesis

        \vspace{1cm}
            
        \LARGE
        \textbf{Re-implementation of the X-Corr algorithm in Python and improvement of scoring using predicted spectra}
            
        \vspace{1cm}

        \LARGE
        \textbf{Author}
        
        Michael Zusmanovskiy, 108019231182
        
        \vspace{1cm}
        
        \LARGE
        \textbf{Supervisors}
        
        Jun.-Prof. Julian Uszkoreit
        
        M.Sc. Dirk Winkelhardt
            
        \vfill
                \begin{figure}[ht]
            \centering
            \includegraphics[width=0.2\textwidth]{figs/medbioinf_logo-small.png}
        \end{figure}
        \begin{figure}[ht]
            \centering
            \includegraphics[width=0.2\textwidth]{figs/Ruhr-Universität_Bochum_logo.svg.png}
        \end{figure}
            
        \Large
        Ruhr-Universität Bochum\\
        
        Submission date: 30. 12. 2024
            
    \end{center}
\end{titlepage}

\tableofcontents
\newpage

\section{Introduction}
\subsection{Fundamentals}
Mass Spectrometry (MS) is a method for measuring the mass to charge ratios (m/z) of components in a chemical substance sample and analysis of its molecules \cite{mass-specrometer}. MS has a variety of applications \cite{ms-applications} reaching from forensic analysis, where it is used to trace evidence , over environmental analysis, for example to keep track of pollution or test drinking water, to clinical purposes where MS is used for proteomics research or diabetes research \cite{ms-diabetes}.
Before mass spectrometry can be performed, the sample has to be prepared meaning that it is turned into a state that is a valid input for the mass spectrometer. This is done by either converting it into a gas phase for Gas Chromatography or into a liquid phase for Liquid Chromatography. In Gas chromatography the molecular components are separated by vaporization and dilution of the sample on basis of attributes like weight, size, or boiling point. Liquid chromatography on the contrary separates components on basis of how fast they travel trough a liquid phase, this can be for example because of the difference of the polarity of the liquid phase and the components of the sample. Of course, the exact workflow is dependant on the Instrument that is used. Mass spectrometers exist in various variants e.G. MALDI-TOF MS, Triple Quadrupole MS, Hybrid Linear Ion Trap Orbitrap MS etc.  \cite{mass-specrometer-types} however regardless of their type they usually follow the same steps \cite{mass-specrometer, what-is-mass-spectrometry}:

\begin{enumerate}
\item After the sample preparation, the sample is ionized, meaning that ions are generated. A common approach in gas chromatography is electron bombardement where the molecules are passed through a ionization chamber with accelerated electrons. The electrons collide with the molecules, break their bonds and turn them into fragments. A different approach in liquid
chromatography is electrospray chromatography where the liquidified sample is sprayed into an electric field where it evaporates.
\item The produced ions are sorted by their mass-to-charge ratios by a mass analyser. How this is done is dependant on the machine that is used.
\item After the sorting of the ions a detection system determines the relative abundances for each observed mass-to-charge (m/z) value.
\end{enumerate} 

The output is a mass spectrum which is an array/matrix that yields the m/z values and their abundances. The m/z value is the mass of a particle divided by its electrical charge. The abundances are commonly normalised to the highest abundance peak in the spectrum, meaning that the highest peak is 1 and all other peaks have a value relative to it [\cref{fig:peptide-example}]. 

Proteins are molecules that have various functions in the human body. They can be in the form of an Antibody, which regulate immune responsivity, by binding to antigens like bacteria or viruses and leading to their destruction. They can also be enzymes, that help regulating metabolism and help with the creation of new molecules by reading the DNA. Proteins can also have a transport function, e.g. communication between cells. Proteins are made out of peptides, which are amino acids chains connected by peptide bonds. There are 20 amino acids in the human body which code every type of protein. Amino acids contain a central Carbon which is bound to a amino group and a carboxylic acid group, hence the name amino acid. 

Tandem mass spectrometry (MS/MS or \(MS^2\)) can be understood as an extension of mass spectrometry. It is used for the analysis of peptides and involves multiple stages, where in the first stage the entire sample is analysed with a mass spectrometer, then one ion is selected for further analysis and on the next stage only this isolated ion is analysed by another MS run \cite{tandem-mass-spectrometry}. This is realized by connecting two analyzers behind each other in "tandem", which are connected by a collision cell. In the first MS run ions are analyzed, those are the so called "precursor ions" and some of then are selected by their m/z value. The selected precursor ions are then even further fragmented into smaller peptide chains by an inert gas, after which they are let into the second spectrometer \cite{tandem-mass-spec-deutsch, tandem-mass-spec-yt}.

Since every peptide sequence produces its own unique mass spectrum through ion fragmentation (which is explained further below), it can be used as its unique fingerprint to identify it in a sample. 
\begin{figure}[ht]
\centering
\includegraphics[width=0.8\textwidth]{figs/peptide.png}
\caption{Measured \(MS^2\) spectrum retireved from the human genome}
\label{fig:peptide-example}
\end{figure}
\begin{figure}[ht]
\centering
\includegraphics[width=0.8\textwidth]{figs/database_search.jpg}
\caption{Peptide identification with the database searching approach \cite{Nesvizhskii2007}}
\label{fig:database-search}
\end{figure}
Tandem MS searching is used for peptide identification within a mass spectrometry scan. Proteomics software that deals with the problem of identifying protein/peptide identification can fall into the category of database searching, where the search is performed against a database of known proteins, and de novo searching, where peptides are deduced without a database. The de novo approach is typically less accurate than the database method, while the database method works only if the selected database with which the search is done, indeed contains the searched proteins/peptides.

This thesis is revolving around the database searching approach. The general concept of tandem MS database searching is described in \cref{fig:database-search}. A spectrum of an experimental precursor ion from an MS/MS run generated by an unknown peptide sequence has a certain mass, if peptides retrieved from a protein database have a mass close to the experimental peptide, the MS/MS spectrum is compared to their "theoretical spectra". To understand how a theoretical spectrum is generated, it is first necessary to understand the concept of ion fragmentation. 

In the collision cell of a mass spectrometer, peptide bonds can be broken in different positions of the peptide, from the N-terminal the a,b,c positions, and from the C-terminal the x,y,z positions. 
\begin{figure}[ht]
\centering
\includegraphics[width=1\textwidth]{figs/ion-frag.png}
\caption{Ion fragmentation \cite{ion-frag}}
\label{fig:ion-frag}
\end{figure}
This is called collision induced fragmentation (CID). In research, Usually the b and y positions are selected for fragmentation, and for this reason, b and y ion fragmentation is used in this research too. In an \(MS^2\) scan each abundant peak that is noticably larger than the noise peaks, optimally is produced by one fragment ion. When annotating a spectrum from the C and N terminal end, the m/z distances are calculated between the most abundant peaks, this can give an insight about one amino acid, and finally the entire peptide sequence \cite{b-y-ions}.

A theoretical spectrum of a peptide from a database is created by the b and y series, for this the sums of the first, then first and second, then first, seconds and third etc. amino acids are calculated, until the end of the peptide sequence, for both the b and y ions, considering charges.

\newpage
% 
\section{Motivation \& Goals}
The goal of this work is to combine the Comet cross-correlation scoring algorithm
with the peptide intensity prediction of MS2PIP to reveal whether replacing the Comet generated theoretical spectrum with the predicted spectrum of MS2PIP will yield better results in peptide identification, and with this, to find a new and possibly even more accurate method of peptide identification.

As Comet is written in the C/C++ Programming Languages and MS2PIP is a Python Api, it is first of all necessary to translate the Comet cross-correlation scoring algorithm to the python programming language as accurately as possible. Next, the theoretical spectrum containing only m/z values without any abundances created by comet will be replaced by the predicted spectrum of MS2PIP. Performance regarding computational speed and identified peptides will be then compared to the initial comet algorithm, and the to python translated comet. 

\newpage

\section{Methods}
\subsection{Comet Xcorr in detail}
Comet is an open source proteomics Tandem \(MS^2\) database search algorithm/tool written in C++ for searching spectrum data against sequence databases and identification of peptides, that in 2012 emerged from the SEQUEST database search tool from the University of Washington that was written in 1994 \cite{comet-search-tool}. It supports multithreading and is highly parametrizable. For the peptide identification the tool computes multiple scores that evaluate how similar a sample peptide spectrum is to a peptide spectrum from a protein database that it is compared to. One of these scores is the "Xcorr", which will be the focus of this thesis. 


To calculate the Xcorr value and other scores the algorithm first performs \textit{in silico} digestion of proteins from a database, meaning that the function of the human digestive system is simulated. In the human body peptides that are too large for the small intestine are cleaved by the enzyme Trypsin, and are called "tryptic peptides". Comet then filters these peptides that have been cleaved off from the database proteins. If a experimental MS2 spectrum has a precursor ion mass of e.g 1500 dalton, the algorithm considers only those peptides from the database that have a mass close to it, e.g with a tolerance of  $\pm$0.005 dalton, meaning that a peptide with a mass of e.g. 1500.001 would be selected for further analysis. All database peptides outside of this mass boundary are discarded.

For these filtered peptides it is assumed that one of them could possibly have generated the sample mass spectrum. The program constructs a spectrum from the peptides by generating all possible m/z values from the 'b' and 'y' series of the peptide, which in the following will be referred to as the theoretical spectrum \cite{comet-first-paper}. 

In the next step Comet computes how similar the sample mass spectrum is to the obtained theoretical spectrum. In science many methods for the computation of similarity between signals are used, e.g euklidean distance or frequency domain analysis, Comet uses the cross correlation approach. Before the cross correlation can be computed, comet preprocesses the sample and theoretical spectrum by a process called "binning". This is for the reason that the spectrum arrays are continuous float values, so it is necessary to turn the spectrum into an array of discrete values to be able to perform a correlation calculation on it. This is described in\cref{fig:binning}, the bin width in this example is 1 and is represented by the x-axis. In the figure the there are two peaks in the bin index 500, that means these peaks have an m/z float value between 500 and 501, e.g 500.1654 and 500.245, and its intensities are 5 and 1. If a bin contains more than one peak, only the highest peak is saved in the binned arrays. In this case the first peak with the intensity of 5 is saved on the index 500. Comet has the option to perform binning with low resolution i.e. a bin size of 1.0005, or high resolution with a bin size of 0.02. 
\begin{figure}[ht]
\centering
\includegraphics[width=1\textwidth]{figs/binning.png}
\caption{The Comet spectrum preprocessing in comet, resulting in a "binned" spectrum \cite{deeper-look-into-comet}}
\label{fig:binning}
\end{figure}
Since in 1994 it was not entirely possible to predict the intensities of 'b' and 'y' ions, the theoretical spectrum is assigned intensities of 50 on the b and y ion generated m/z positions \cite{deeper-look-into-comet}. For the sake of slightly increasing tolerance and making the theoretical spectrum peaks similar to a "bell shape", neighboring m/z values, meaning $\pm$1 m/z, receive an intensity of 25. 

After the binning stage, the binned experimental sample spectrum is further processed, the binned experimental spectrum is divided in 10 equal windows, inside of each of these windows, all values are normalised between 0 and 50, meaning that the highest peak receives an intensity of 50, and all other peaks in the bin receive a value relative to it. This is done for the purpose of making the experimental spectrum look similar to the theoretical spectra, and enhance possibly relevant peaks. This step was not proposed in the inital paper but was implemented with the help of the original authors.

Cross correlation is performed on experimental and theoretical spectra, the function can be described by the following mathematical expression:

\[R_{x,y}(\tau)=\displaystyle\sum_{i=0}^{n-1}x(i)y(i-\tau)\]

Here x and y are the binned experimental and theoretical spectrum arrays and \(\tau\) the shift parameter over the range \(-75 < \tau < 75\).

For the Xcorr score, the similarity at zero offset \(\tau=0\) is first determined, after that the binned arrays are shifted by $\pm$75 m/z and the correlation is determined at each offset.
The background similarity is defined by computing the mean of all correlation values without the one at zero offset. The xcorr is then similarity at \(\tau=0\) minus background similarity \(\overline{-75<\tau<75},\tau\neq0\) \cite{xcorr-function}.



\subsection{Reference Comet run}
To later compare the identified peptides and the performance of the original Comet implementation and this implementation, a reference run with the original Comet search tool was performed. The Comet version "2021.01 rev. 0 was used. 

 For this reference comet run, LFQ Orbitrap data was used as the sample, specifically in the mzML format, which is a xml based format for storing mass spec scan data. Each scan has a unique scan id and contains binary coded information about the scan start time, MS level, base peak m/z and intensity, lowest and highest observed m/z, the m/z array and the intensity array e.t.c.. In case of a \(MS^2\) scan, it additionally contains information about the selected precursor ion(s) like e.g. its charge state. The exact file was obtained from \textbf{https://ftp.pride.ebi.ac.uk/pride/data/archive/2022/02/PXD028735/} , the name of the used file is "LFQ\_Orbitrap\_DDA\_Human\_01.raw". The file was converted to the mzML format by msconvert running on docker, vendor peak picking on all MS levels was used.

The search was done against data of the Homo sapiens (Human) proteome in the fasta format which stores protein sequences and serves as the "database". Each protein entry inside the file has a header with a unique name, id and description. The used fasta file was acquired from the uniprot knowledgebase and has the id UP000005640 ( \textbf{https://www.uniprot.org/proteomes/UP000005640} ).

The number of used processing threads was set to 10, the peptide mass tolerance was set to 20 parts per million (ppm), the amount of missed cleavages was set to 2, the valid ms level is set to two. The run was done with high resolution binning, that means a bin width of 0.02 was used. The variable modification oxidation of the amino acid methionine (M) and static modification carbamidomethylation of cysteine (C) were considered.

\subsection{Peptide intensity prediction}
Peptide prediction algorithms are able to predict \(MS^2\) peaks from given peptide sequences with the help of various machine learning models trained on large amounts of \(MS^2\) PSM (peptide spectrum match) data. A PSM is a score which is close to zero when a peptide has been falsely identified and is likely to be a false match and occurred by chance. A high PSM score, meaning a score close to 1, implies that a match is unlikely to have occurred by chance and that it is likely that a match is correct. 

MS2PIP\cite{ms2pip, ms2pip-server} (short for \(MS^2\) peak instensity prediction) is a peptide intensity prediction tool which has a running server version and also exposes a Python API. MS2PIP has multiple built-in prediction models which differ in instruments, fragmentation method, modifications, and labeling techniques; the supported models are HCD, HCDch2, CID, CIDch2, iTRAQ, iTRAQphospho, TMT, and TTOF5600. Each model was trained on different training-test datasets and evaluation datasets of different amounts of PSMs including proteins from human, rat, mouse, plant and bacteria \cite{ms2pip}. The models were trained with regression learning with the use of a feature vector, for this the training dataset was divided by the charge states 2 and 3, since these are the most common occurring ion charges, and by the peptide length between 8 and 28 amino acids. Features like n-terminal labeling, peptide m/z value, fragment ion m/z value, number of accurance of an amino acid in the, peptide e.t.c. have been taken into account for the feature vector. Each PSM is then assigned a set of features in the feature vector and labeled with a target. Regression models for multiple types of fragment ions, including b and y ions which are the fragment ions focused on in this thesis, have been constructed. The training data spectra are searched for fragment ion peaks with a tolerance of 0.8 Dalton, in case multiple peaks are present in this range, only the highest is selected as the matching peak. A training data set is collected for every fragment ion that holds all PSMs fitting the charge and peptide length of the fragments, the peak intensities are assigned to the training set as its targets. For each ion fragment the training data set is merged from multiple experimental spectra by merging the peak intensities, to eliminate redundant PSMs. If in a PSM a peptide sequence exists more that 10 times, this PSM is removed to reduce e.g. random matches.

The regression method that was used is the random forest method, for this the R library "randomForest" was utilized. The predicted peak intensities were retrieved as the average of all regression tree forest outputs.

Random Forest \cite{random-forest} is a regression/classification technique based on decision trees that usually start with the tree root node at the top and split up in two decisions (= Two nodes below connected by edges). Every node is split up until a leaf node is reached at the bottom of the tree. To create a random forest tree new datasets are created by randomly selecting data (=random sampling, hence the name random forest) from the original dataset, this prevents overfitting to the original data and increases generalization. These datasets are called bootstrapped datasets, and for each created dataset a decision tree is generated, based on only a subset of features from the original dataset. The trained result is the average of the outputs of all trees. Depending on the used tool, a random forest can be set up by a set of parameters, the most common are the maximum tree depth, maximum features, and the number of used decision trees.

The MS2PIP tool is able to predict the m/z values given a peptide (with static and variable modifications) and its precursor charge, and also its intensities. This will be in the following referred to as the "predicted spectrum" of a peptide.

\subsection{Used Python Libraries}
The following Python packages have been used in the reimplementation:
\begin{itemize}
    \item \textit{typer} (version 0.15.1) is a tool for building CLI's.
    \item \textit{pyteomics} (version 4.7.5) This package contains many tools for analysis of proteomics data \cite{pyteomics, pyteomics-five-years}
    \item \textit{numpy} (version 1.26.4). Numpy (Numerical Python) is a package for efficient work with datastructures like matrices and arrays.
    \item \textit{lxml} (version 5.3.0). The lxml package is necessary for the pyteomics package to process xml based languages.
    \item \textit{ms2pip} (version 3.13.0). MS2PIP is a python package for peptide fragmentation spectrum prediction.
    \item \textit{pandas} (version 1.5.3) . Pandas is a python library for data analysis and data manipulation.
    \item \textit{scikit-learn} (version 1.6.0) This package is used for various scientific purposes like machine learning.
\end{itemize}

\newpage

\section{Results}

\subsection{Reimplementation of the Xcorr algorithm in Python}
As already mentioned in the Goals section, Python is selected as the programming language for this work.

\subsubsection{Reading in Spectrum data}
To compare the reimplementation with the original comet, the exact same mzML and FASTA files were used as in the reference Comet run. Acessing these files with Python was done with the help of the pyteomics python framework. Pyteomics has \textit{read} functions for parsing mzML and FASTA files. The \textit{fasta.read} function returns an iterator of tuples, of which the first entry is the header and the second one the sequence. The \textit{mzml.read} function returns an iterator with spectrum properties.

\subsubsection{Creating a peptide index list}
For efficient identification of peptides it is first necessary to create a compact list that contains all masses, and peptides that have this mass, from the FASTA database file. In the following this list will be referred to as the "peptide index". While iterating through the FASTA database, the retrieved sequences are \textit{in silico} digested. This digestion is realized by cutting the sequences after the amino acids Arginie (R) and Lysine (K), except for those sites where R or K are followed by Proline (P). The general regular expression for this is "(?$<$=[KR])(?!P)". For this matter, the pyteomics library function \textit{parser.cleave} was used, for each peptide that was cleaved off, the resulting peptide length is restricted between 6 and 50 amino acids, and a maximum of 2 missed cleavages is allowed, meaning that at most two spots that are matched by the regular expression are "overlooked". 

The resulting peptides are all in an unmodified state, so for the program to recognize possible modified peptides in a scan from the mzML\cite{mzml} file, it is necessary that for every peptide that has been cleaved from a sequence from the FASTA database file, all its isoforms are generated. Isoforms are proteins that have been produced by the same gene and have an identical composition but have a different structure. In this case, isoforms refers to one peptide but with all combinations of post-translational modifications. Those peptides that contain an "X", i.e. an unspecific amino acid, are ignored. The generation of isoforms is achieved by the pyteomics library function \textit{isoforms} from the parser module, which takes in one peptide cleaved from the database at a time, applies fixed modifications i.e. modifications that are always applied, and variable modfications, for which all possible combinations are generated. Exemplary like in the reference comet run, the static modifications Carbamidomethylation of Cysteine (C) as well as the variable modification Oxidation of Methionine (M) have been taken into account. The amount of maximum modifications is set to three, meaning that in one peptide at most three amino acids can be affected by a variable modification.

For every generated isoform, the mass is calculated. This mass is added to a dictionary as the key if it does not exist in the dictionary yet, and the according peptide as the value. Since multiple peptides can have the same mass, it is possible that for a mass/key value are multiple peptides stored. Next, the dictionary is converted to list which is sorted by the mass in ascending order [\cref{fig:peptindex}]. The reason for this is that a python dictionary is unordered and "unindexable", and since binary search will be performed in the following on the peptide index, it is necessary to convert the dictionary into an indexable list.
 
\subsubsection{Multiprocessing}
After generating the peptide index list, a pool of user specified amount of processes is created in order to increase performance and use as many computer resources as possible. A \textit{manager} from the python multiprocessing library is used to share the previously generated peptide index between the pool processes. 

The program starts iterating over the spectra inside the mzML sample file, and does so until all spectra are read. It loads user defined amount of spectra into a buffer, which is accessed by the process pool. A process loads one spectrum scan from the buffer and proceeds with the identification, meaning that the peptide index is searched for a possible close match for the spectrum.
\begin{wrapfigure}{r}{0.5\textwidth}
\includegraphics[width=\linewidth]{figs/peptindex.png} 
\caption{Peptide index list generated from the fasta database file}
\label{fig:peptindex}
\end{wrapfigure}
\subsubsection{Filtering of candidate peptides}
Each single process calls the \textit{identification} function, which does the following:
It iterates over the tree structure of a scan from the mzML file, and it is first checked whether the MS level is 2, i.e an \(MS^2\) scan, since the file contains scans of various MS levels. If this is the case, the program iterates over all possible precursors, where it first calculates the mass in Dalton of the selected ion from the retrieved mass to charge and charge values. This is done by the calculation \begin{math}(mz * charge) - (hydrogen\_mass * charge)\end{math}.

The program proceeds with a rough filtering of peptides that can come into question for the given scan. This is done by a lookup into the peptide index where it is searched for peptides that have a mass close to the mass of the selected precursor ion. The tolerance for a canditate peptide is 20 parts per million (ppm), that means between a mass of $\pm$ (precursor mass * 0.00002). The lower and upper tolerance bounds in Dalton are calculated by the \textit{tolerance\_bounds} function. 

The peptide index is a list meaning that it is indexable, and the masses are sorted in ascending order, that means that it is possible to efficiently get the upper and lower indices of the peptide index entries by performing binary searching on the list. A binary search function is searching for the lower index of the peptide list first, and returns the first index of the list where the mass is $\ge$ the calculated lower bound. The upper index is searched the same way. After getting the upper and lower indices, the process gets a slice from the peptide index including all peptides that are possible candidates for scoring. E.g if the lower bound for the mass is 1033.6777 and the upper bound is 2190.5454, the slice would be between the second line and the second last line in \cref{fig:peptindex}.
\begin{wrapfigure}{r}{0.5\textwidth}
\includegraphics[width=\linewidth]{figs/crosscorr.jpg} 
\caption{Preprocessing the binned arrays before correlation calculation}
\label{fig:corr}
\end{wrapfigure}

\subsubsection{Spectrum binning}
The mass-to-charge values and its corresponding intensities are retrieved as two separate numpy arrays from the mzML file and are sorted in parallel in a way that the m/z values are in ascending order, and every m/z value in the m/z array has its intensity stored in the intensity array on the exact same index.

The process continues with what in the original comet implementation is referred to as "binning". First, the values in the intensity array are normalised between 0 and 50. Depending on the bin size, the bin index of a m/z value is calculated by dividing the m/z by the bin width. A numpy bin array is created, its size depending on the biggest m/z value in the m/z array, and since an m/z array from the sample mzml file can have values up to 2000, the bin array can have a size of 100.000. The bin array is filled with the intensites from the intensity array on the calculated index. In case there are 2 intensities on the same index, like in the comet implemenation, only the highest intensity is stored. Like in comet, the binned experimental array is processed by dividing it into 10 equal sections and normalisation is performed within them.

The program now proceeds with generating theoretical spectra by computing fragment m/z values for every peptide from the previously retrieved peptide index list slice with candidate peptides. This is done by a seperate function for every peptide in the slice which takes in the peptide as a string and the maximum charge of the selected precursor ion - 1 as the parameters. Like in the initial reference comet run, the maxcharge is limited to 3. The fragmentation function returns a list with m/z values, which is the theoretical spectrum of the candidate peptide, and binned the same way as the spectrum retrieved from the sample mzml file, except that this fragmentation m/z list has no corresponding list containing intensities. In this case the bin array index is calculated the same way, but on the index position the bin array is filled with a 50, and neighboring bins are filled with a value of 25. 

\subsubsection{Peak intensity prediction with MS2PIP}
In case the user of the tool decides to run the program with predicted spectra instead of the theoretical spectra, the program runs the \textit{predict\_spectrum} function on the peptides. The Pyteomics library and the MS2PIP library have different ways of labeling/marking modifications of a peptide. 

Pyteomics uses the modX peptide representation which is an extension of the standard one letter peptide sequence representation. A modX label is either a regular one letter upper case amino acid or a modified amino acid, which starts with a random amount of lower case letters marking a modification, and ending with a single upper case letter which is the modified amino acid. Examples for a modX Label are "carbC", "oxidM" or "A". MS2PIP uses formatted modification strings to mark modifications of a peptide. An exemplary mod-string is \begin{math}2|Carbamidomethyl|4|Oxidation|10|Oxidation\end{math}, where the integer value is the position and string next to it the modification name. In the case that a peptide has no modifications, the string "-" is used. 

To translate between the two notations, the peptide retrieved from the peptide index has to be parsed by a Pyteomics parser which takes in a Pyteomics formatted peptide string and returns the peptide as a list of labels, this list is then iterated over and a MS2PIP style-formatted modification string is generated. The plain isoform of the peptide and its modification string as well as the specified prediction model which in the default case is HCD, are then fed into the MS2PIP \textit{predict} function, which returns an array of predicted m/z values and its corresponding predicted intensity array, i.e. the predicted spectrum of the peptide.

\subsubsection{Xcorr scoring}
After the sample spectrum and the theoretical spectrum have been binned, they have to be brought to the same length. This is achieved by filling up the binned theoretical spectrum with zeros in case it is smaller than the binned sample spectrum. If the binned sample array is smaller, it is simply cut to the right length. 

In the Comet implementation the binned sample and binned theoretical spectrum are shifted by $\pm$75 Dalton, which corresponds to a shift size of 75/0.02 bins, where at each overlap the correlation is calculated. This is achieved by appending the shift size amount of zeros on the first and last index on one of the arrays and the \textit{correlate} function from the numpy library with the mode "valid". The resulting array has a size of 3750 + 3750 + 1 = 7501, a shift of 3750 bins in each direction and the dot product at zero offset. The correlation at zero offset corresponds to the entry at index 3750 in the resulting array, which is exactly the middle entry. To calculate the background similarity, the entry at the middle index is removed and the mean over all remaining entries in the correlation array is calculated. The Xcorr score is computed by subtracting the background similarity from the similarity at zero offset, then divided by 10.000.[\cref{fig:corr}].

\subsubsection{Output}
The process returns and adds all identified results for a peptide from the sample mzML file to a result list. When the buffer is fully consumed, all results are printed to a TSV file in tab separated format. One result consists of the scan number which is unique for every entry inside of the sample mzml file, the charge of the precursor ion, the mass of the experimental neutral precursor ion from the mzml file, the calculated neutral mass of the theoretical peptide that has been selected for matching, the Xcorr score, the amount of matched ions, meaning the amount of sites where on zero shift there are non-zero values in both binned arrays, the amount of total ions of the theoretical spectrum and the peptide which can also contain modifications.

\subsubsection{CLI}
To make usage comfortable, a CLI is implemented. This was done with the help of the Typer Python library. The general usage is defined as "cli.py [OPTIONS] SAMPLE\_FILENAME PROTEIN\_DATABASE" in the terminal, where "SAMPLE\_FILENAME" is a required argument and placeholder for the sample filename in the mzml format as a string, and "PROTEIN\_DATABASE" the string for the database filename respectively, in the fasta format. 

The CLI provides additionally three options: The "--p" flag followed by an integer sets the amount of processes to use for multiprocessed identification. If this flag is not set, the program works with a default value of cpu\_count()-2, where cpu\_count() returns the amount of processes the used machine can provide. The "--s" flag followed by an integer specifies the amount of spectra that the processes load and buffers at a time. The default amount is 5000. If the "--ps" flag is set, the program will work with the predicted spectra instead of the theoretical ones.

The user can get a help-text by typing "python xcorrcli.py --help" in the terminal, which contains the above mentioned information.

\subsection{Comparison}
To compare the execution times and identification of comet and this implementation, a small fasta database file was created, which contains the top 110 peptides that resulted in the best scores in the initial previously described comet run. Both versions of the Python program were run with the exact same parameters with a ssh remote connection on a virtual server in a data center.
An exemplary output of the Python program is shown in \cref{fig:output}, sorted in descending order by xcorr scores.
\begin{figure}[ht]
\centering
\includegraphics[width=1\textwidth]{figs/output.png}
\caption{An example output of the program, used theoretical spectra for identification}
\label{fig:output}
\end{figure}

\subsubsection{Identification comparison}
Although the reimplemented Xcorr scores are not exactly matching with the scores of the original Comet implementation, it manages to compute scores that are very similar to the ones in Comet. This is demonstrated in \cref{fig:scatterplot}. The x-axis represents the scores produced by the Python program, the y-axis the scores of Comet. For this plot only the highest score was selected for every scan number, this was achieved by sorting the scores in descending order and applying the \textit{drop\_duplicates} function from the Pandas library. Inner join was then performed on both results by Pandas to create a list containing only one score entry for each method for each scan number. The \(R^2\) score is 0.9967, which was calculated by the sklearn function \textit{r2\_score}.

The scatter plot dots align mostly in a straight diagonal line, which demonstrates that the scores of the python Program are close to the scores of comet. The scatter plot also contains outliers which shows that some scores are not matching, the reason for the not exact matching is that comet has additional steps in preprocessing the binned spectra, and comet also uses a fast scoring algorithm which was not taken into account in this Python implementation. 
\begin{figure}[ht]
\centering
\includegraphics[width=0.8\textwidth]{figs/scatterplot.png}
\caption{Scatterplot between the comet xcorrs and in Python replicated xcorrs. For each scan number in the results only the highest xcorr value was selected. \(R^2\) = 0.9967}
\label{fig:scatterplot}
\end{figure}

Now that the scores generated by the Python program using theoretical spectra are close to the scores in Comet, a comparison between scores using predicted spectra with MS2PIP can be done. The scores of the Python program with the theoretical spectra have been plotted against the scores using predicted spectra with the HCD model in \cref{fig:scatterplot_predicted_theoretical}, the \(R^2\) score is -1.019. The HCD Model was used for the reason that it is the default MS2PIP prediction Model and has been trained on the largest training data set. As expected, the correlation between both scorings is low: A theoretical spectrum of a peptide has more peaks than a predicted spectrum, this leads to lower average scores when matching an experimental spectrum with a predicted spectrum.

\begin{figure}
\centering
\begin{subfigure}[b]{1\textwidth}
    \includegraphics[width=0.7\textwidth]{figs/scatterplot_predicted_theoretical.png}
   \caption{}
   \label{fig:scatterplot_predicted_theoretical} 
\end{subfigure}
\begin{subfigure}[b]{1\textwidth}
   \includegraphics[width=0.7\textwidth]{figs/scatterplot_windows.png}
   \caption{}
   \label{fig:scatterplot_windows}
\end{subfigure}
\caption{(a):Scatterplot between the scores using theoretical spectra and predicted spectra in the python reimplementation. For each scan number in the results only the highest xcorr value was selected. \(R^2\) = -1.019 (b): with normalisation in 10 windows \(R^2\) = -0.079 \cref{fig:output}}
\label{scatterplot_python}
\end{figure}
An example for a good match is shown in \cref{predandtheo}. The blue peaks represent the experimental spectrum from the scan 71120, and the red peaks are the theoretical spectrum for the peptide "LAADEDDDDDDEEDDDEDDDDFDDEEAEEKAPVK". As can be seen, most of the red theoretical spectrum peaks in \cref{predandtheo}(a) align with the most abundant blue peaks. In this case, 60 of the total 140 theoretical spectrum ion peaks match a blue peak. 

For the predicted spectrum matching in \cref{predandtheo}(b) for the same scan, 70 red peaks were predicted in total by MS2PIP, 25 of which are matching the peaks of the blue experimental spectrum.

\cref{predandtheocorr} demonstrates that the highest correlation was calculated at zero offset of both the experimental and theoretical/predicted spectra. There are notably fewer background similarity peaks in the correlation array of the predicted spectrum, demonstrating that the predicted spectrum is more accurate than the theoretical one.

All of this are high indicators that the experimental spectrum with scan number 71120 might indeed be produced by the peptide "LAADEDDDDDDEEDDDEDDDDFDDEEAEEKAPVK".

Despite the predicted spectrum closely matching the experimental spectrum in \cref{fig:predict}, the score is much lower then the score for the theoretical spectrum match. This score is also not high in comparison to other scores using predicted spectra, which go up to 13.8. This is caused by the normalisation of the entire spectrum to the highest peak, in \cref{fig:predict} exist three peaks that are significantly more abundant than the rest of the peaks, which are small in comparison. The products between most of the binned array entries are low, which leads to a low Xcorr score. This is also apparent in \cref{fig:scatterplot_predicted_theoretical}, which shows that there is almost no correlation between the scores for the predicted and theoretical matching. The reason for this is that peptide prediction generally generates less ions than in a theoretical spectrum.

To address this problem, the same approach as in comet is used. Instead of normalising both predicted and experimental spectra to the highest peak over the entire m/z interval, both of the spectra are divided into ten equally long windows, and on each of these windows normalisation is performed. \cref{fig:scatterplot_windows} shows the correlation of the scores after applying window normalisation. The correlation is still low, but it is more restrained in the diagonal direction, and the \(MS^2\) score is calculated as -0.079. The scores for the predicted peptide matching have also been lifted up by this. The plot for the scan 71120 after performing window normalisation on predcited and experimental spectrum is shown in \cref{fig:scanwin}.

\begin{figure}
\centering
\begin{subfigure}[b]{1\textwidth}
    \includegraphics[width=0.95\textwidth]{figs/scan_71120_ps=False.png}
   \caption{}
   \label{fig:theo} 
\end{subfigure}
\begin{subfigure}[b]{1\textwidth}
   \includegraphics[width=0.95\textwidth]{figs/scan_71120_ps=True.png}
   \caption{}
   \label{fig:predict}
\end{subfigure}

\caption{(a): Plot of an experimental processed spectrum (blue) and theoretical spectrum (red). (b): experimental (blue) and predicted spectrum (red) for scan 71220 in \cref{fig:output} . The x-axis represents the binned m/z array indices, the y-axis the intensities normalised between 0 and 50. Red colored spectra are presented negative only for visualization purposes.}
\label{predandtheo}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}[b]{1\textwidth}
    \includegraphics[width=0.95\textwidth]{figs/corrtheo.png}
   \caption{}
   \label{fig:corrtheo} 
\end{subfigure}
\begin{subfigure}[b]{1\textwidth}
   \includegraphics[width=0.95\textwidth]{figs/corrpredict.png}
   \caption{}
   \label{fig:corrpredict}
\end{subfigure}
\caption{(a): Plot of correlation array returned by the numpy \textit{correlate} function for match with theoretical spectrum (b): with predicted spectrum. The x-axis represents the correlation array index, the y-axis the correlation.}
\label{predandtheocorr}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=0.8\textwidth]{figs/scan_71120_ps=True_wins.png}
\caption{Matching predicted spectrum with experimental spectrum for scan 71120 after window normalisation}
\label{fig:scanwin}
\end{figure}

The MS2PIP prediction models HCD, TMT, iTRAQ and CID have been selected for analysis for the reason of having the top 4 median pearsson correlation values on their used evaluation dataset.
To measure the accuracy of theoretical spectrum matching against predicted spectrum matching, the ratio between total ions produced to ions matched is compared between the two methods. For this, the value ions\_matched is divided by the value ions\_total in \cref{fig:output}. The intensity accuracy is not taken into account in this comparison. \cref{fig:ratio_table} shows that all the selected MS2PIP prediction models achieve roughly the same matched to total ratio while only predicting less than half of m/z values. Interestingly, all the models predict the same amount of m/z values, hence the same average amount of total ions. The highest ratio was achieved by the iTRAQ model.

\begin{figure}[ht]
\centering
\includegraphics[width=1\textwidth]{figs/ratio_table.png}
\caption{Average Ions Total, Ions matched and the Ratio for theoretical spectrum matching and four examplary MS2PIP prediction models.}
\label{fig:ratio_table}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=1\textwidth]{figs/ident-comparison.png}
\caption{Comparison of the top identified scans in each method, between the other methods.}
\label{fig:ident-comparison}
\end{figure}

In \cref{fig:ident-comparison} the top identified scans in each method are compared between the other methods. For this, the top scan number in each method was noted in the "Top in" and "Scan" columns, where "Top in" is the method and "Scan" in the same row is the spectrum that has the best score using that method. "Theo" here means "Theoretical spectrum matching, "pred" predicted spectrum matching. 
The scan 71120 ranked first using theoretical spectrum matching mode, while with the prediction model HCD it ranked 39th, in TMT 212th, iTRAQ 437th and CID 155th. The models TMT, iTRAQ and CID share the same top ranked scan, 93039.

\subsubsection{Performance comparison}
Early into the development it was clear that the speed of the Python reimplementation would be slower than the original C++ program. The main reason for this is the programming languages that were used. 

Although Python might be considered a comfortable and faster language for development by some people, it is a higher level language than C++. Python is a interpreted language, meaning that code is interpreted at run-time, while C++ is a compiled language and the code is already translated to machine language before execution. C++ programs are running directly on the hardware of the system, so there is no intermediate layer. Python programs have an interpreter as an intermediate layer, which leads to additional overhead.

C++ programs are running directly on the hardware of the system, so there is no intermediate layer. Python programs have an interpreter as an intermediate layer, which leads to additional overhead.

Memory management is different in Python and C++, while C++ gives the developer more control over memory allocation than python, the performance of python on the other hand can suffer for the reason of object immutability, because it increases memory usage. 

The difference in runtime optimization is a reason for the speed difference as well: C++ code is optimized mostly at compile time, this can be e.g. loop unrolling or function inlining. Pythons standard interpreter doesn't perform optimization like this. The Type system in both programming languages is different, in C++ the variable data types are static, that means that a variable is assigned a definite data type, which can help the compiler in optimization. Python has the dynamic data type system i.e. the data type of a variable is determined at the runtime, which has a certain time cost.

At this point it needs to be noted that Python was not selected as the programming language for the sake of execution speed, but because of compatibility with the MS2PIP peptide prediction tool, and for the reason of faster and easier prototyping.

The fast scoring algorithm of comet has not been implemented in this python version, which is one of the reasons for the slower performance.

To detect the optimal amount of processes to use for a computation, the program was run in both theoretical and prediction modes at different amounts of processes, and the execution times were noted. For the prediction mode, multiple MS2PIP models were tested. The execution times are shown in \cref{fig:speed-comparison}. An issue with MS2PIP is that the funtions used from this module seem to starting processes by their own, and this multiprocessing cant be controlled by the user. Which results in a very high amount of processes in total and leads to many processes contending for computation time. The numpy library uses multithreading by default too. This means that running the Python program with too many pool processes will slow it down, which is also demonstrated in \cref{fig:speed-comparison}. The optimal amount of processes to use for the Python program is identified as 4 for the theoretical spectrum matching mode, whose execution time lies at 0:13:13. For the four tested prediction models the optimal amount of processes is identified as 3-4, exemplary, HCD and iTRAQ were run at different amounts of processes for this. Using more or less processes than 4 will not be beneficial for the execution speed. The speed of all prediction models, python theoretical spectrum matching and comet was compared at 4 processes.

\begin{figure}
\centering
\includegraphics[width=1\textwidth]{figs/speed-comparison.png}
\caption{Computation speed comparison for comet and the python reimplementation in both modes and models.}
\label{fig:speed-comparison}
\end{figure}

\newpage

\section{Discussion and Conclusion}
\subsection{Evaluation}
In the result section of this thesis the speed and identification of the use of theoretical spectra versus the use of predicted spectra have been compared, where it has been shown that the reimplemented Python tool can detect peptides that are not detected by comet, and the m/z prediction of all tested MS2PIP models have a higher accuracy.

It also became apparent that the Python reimplementation is significantly slower than the original C++ counterpart, especially with the prediction of peptide intensity.

While peptide spectrum prediction can often be more accurate than using a theoretical spectrum of a peptide for matching,
it has a drawback: Theoretical spectra are always correct for a given peptide, that means given a peptide and a precursor charge state, an unambigous theoretical spectrum can be generated. Peptide intensity prediction on the other hand can predict the m/z vallues as well as the corresponding intensities wrong.

Considering the long execution time of a database search run with peptide prediction, but also its advantage of uncovering peptides not found with theoretical spectrum matching, a balanced approach can be taken and the scoring with peptide intensity prediction can be used for validation of a theoretical spectrum matching database search run. When a certain score threshold has been reached, the program can proceed to score with peptide prediction, and check whether the result is positive too.

Since there is an obvious tradeoff between execution time and the accuracy of the Prediction models, this is a matter that has to be decided by the user.

\subsection{Future Work}
Regarding the speed factor of this implementation, it is necessary to implement the fast scoring array manipulation like it is used in Comet to increase execution speeed. 

Speed can also be greatly increased by implementing sparse arrays like they are used in comet. In this implementation, after the binning stage of either the theoretical, predicted or experimental spectra, the resulting binned arrays have a length of about 100.000, of which about 99\% values contain zeros. This is highly impractical and can significantly slow down the execution time of the program, considering that the calculation of correlation on these binned arrays has to be done hundred thousands of times in one program run.

It is neccessary to solve multiprocessing issues, the numpy library as well as the MS2PIP multiprocessing need to be configured in such a way that additional processes/threads are not created in an uncontrolled way. The more pool processes this implementation uses, the faster it should become.

Comet uses multiple scores to evaluate peptide matches, e.g. the e-value of the sp\_score , so one of the key points for future work is implementing more scores with the usage of predicted spectra as well.

For the estimation of false positives comet has implemented decoy-search, this is done by reversing peptide sequences, keeping their N or C-Terminal amino acids in place, and adding these reversed peptides to the search. False positive estimation like this can lead to better identification quality.

More modifications can be considered in the future, including N and C Terminal modifications.

Since comet is highly parametrized and thus gives the user a high amount of flexibility with the program, more parameters need to be implemented in this program.

Other prediction tools can be tried in the future with different algorithms.

\subsection{Documentation}
All source code is provided on \textbf{https://github.com/medbioinf/xcorr-reimplementation} , and for the description of the functions and modules in the written code, the numpy styled documentation "numpydoc" was used. Based on this, an HTML documentation with the sphinx tool is generated. The parameters, return types and exception raises are well documented.

\newpage

\printbibliography

\end{document}
